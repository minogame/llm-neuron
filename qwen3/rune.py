import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
os.environ["TRANSFORMERS_NO_TF"] = "1"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"
os.environ["USE_TF"] = "0"

from transformers import AutoTokenizer
from modeling_qwen3 import Qwen3ForCausalLM, Qwen3ForNeuronSignal
import sys, torch
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
from prepare_data import DataProcessor
from draw import DrawNeuron, DrawFFT
import numpy as np
from sklearn.metrics import r2_score
import itertools

model_name = "Qwen/Qwen3-0.6B"
# model_name = "Qwen/Qwen3-1.7B"
# model_name = "Qwen/Qwen3-4B"
# model_name = "Qwen/Qwen3-8B"

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)

model = Qwen3ForNeuronSignal.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)

n_model_layers = model.config.num_hidden_layers


# model = Qwen3ForCausalLM.from_pretrained(
#     model_name,
#     torch_dtype="auto",
#     device_map="auto"
# )

# # sentence = (
# #     "<think>"
# #     "Okay, the user wants a short introduction to a large language model. Let me start by recalling what I know about LLMs. They're big language models, right? So I should mention their ability to understand and generate text. Maybe start with the basics: how they work. Then explain their capabilities, like answering questions, creating content, etc. Also, highlight their advantages over traditional models. Oh, and maybe touch on their applications in various fields. Keep it concise but informative. Make sure it's clear and easy to understand. Avoid technical jargon. Let me structure it in a way that flows well from introduction to main points."
# #     "</think>"
# #     "A large language model (LLM) is a type of artificial intelligence system designed to understand and generate human language. These models are trained on vast datasets to comprehend complex texts, answer questions, and create creative content. They are capable of tasks like writing essays, generating stories, or even translating languages. Unlike traditional models, LLMs can process and respond to a wide range of inputs, making them versatile and powerful for various applications in fields like healthcare, education, and beyond."
# #     "<|im_end|>"
# # )

sentence = """
Inventors have long dreamed of creating machines that think. This desire datesback to at least the time of ancient Greece. The mythical ﬁgures Pygmalion,Daedalus, and Hephaestus may all be interpreted as legendary inventors, andGalatea, Talos, and Pandora may all be regarded as artiﬁcial life (Ovid and Martin,2004; Sparkes, 1996; Tandy, 1997).When programmable computers were ﬁrst conceived, people wondered whethersuch machines might become intelligent, over a hundred years before one wasbuilt (Lovelace, 1842). Today,artiﬁcial intelligence(AI) is a thriving ﬁeld withmany practical applications and active research topics. We look to intelligentsoftware to automate routine labor, understand speech or images, make diagnosesin medicine and support basic scientiﬁc research.In the early days of artiﬁcial intelligence, the ﬁeld rapidly tackled and solvedproblems that are intellectually diﬃcult for human beings but relatively straight-forward for computers—problems that can be described by a list of formal, math-ematical rules. The true challenge to artiﬁcial intelligence proved to be solvingthe tasks that are easy for people to perform but hard for people to describeformally—problems that we solve intuitively, that feel automatic, like recognizingspoken words or faces in images.This book is about a solution to these more intuitive problems. This solution isto allow computers to learn from experience and understand the world in terms ofa hierarchy of concepts, with each concept deﬁned through its relation to simplerconcepts. By gathering knowledge from experience, this approach avoids the needfor human operators to formally specify all the knowledge that the computer needs.The hierarchy of concepts enables the computer to learn complicated concepts bybuilding them out of simpler ones. If we draw a graph showing how these concepts
are built on top of each other, the graph is deep, with many layers. For this reason,we call this approach to AI deep learning.Many of the early successes of AI took place in relatively sterile and formalenvironments and did not require computers to have much knowledge aboutthe world. For example, IBM’s Deep Blue chess-playing system defeated worldchampion Garry Kasparov in 1997 (Hsu, 2002). Chess is of course a very simpleworld, containing only sixty-four locations and thirty-two pieces that can movein only rigidly circumscribed ways. Devising a successful chess strategy is atremendous accomplishment, but the challenge is not due to the diﬃculty ofdescribing the set of chess pieces and allowable moves to the computer. Chesscan be completely described by a very brief list of completely formal rules, easilyprovided ahead of time by the programmer.Ironically, abstract and formal tasks that are among the most diﬃcult mentalundertakings for a human being are among the easiest for a computer. Computershave long been able to defeat even the best human chess player but only recentlyhave begun matching some of the abilities of average human beings to recognizeobjects or speech. A person’s everyday life requires an immense amount ofknowledge about the world. Much of this knowledge is subjective and intuitive,and therefore diﬃcult to articulate in a formal way. Computers need to capturethis same knowledge in order to behave in an intelligent way. One of the keychallenges in artiﬁcial intelligence is how to get this informal knowledge into acomputer.Several artiﬁcial intelligence projects have sought to hard-code knowledgeabout the world in formal languages. A computer can reason automatically aboutstatements in these formal languages using logical inference rules. This is known astheknowledge baseapproach to artiﬁcial intelligence. None of these projects hasled to a major success. One of the most famous such projects is Cyc (Lenat andGuha, 1989). Cyc is an inference engine and a database of statements in a languagecalled CycL. These statements are entered by a staﬀ of human supervisors. It is anunwieldy process. People struggle to devise formal rules with enough complexityto accurately describe the world. For example, Cyc failed to understand a storyabout a person named Fred shaving in the morning (Linde, 1992). Its inferenceengine detected an inconsistency in the story: it knew that people do not haveelectrical parts, but because Fred was holding an electric razor, it believed theentity “FredWhileShaving” contained electrical parts. It therefore asked whetherFred was still a person while he was shaving.The diﬃculties faced by systems relying on hard-coded knowledge suggestthat AI systems need the ability to acquire their own knowledge, by extracting
patterns from raw data. This capability is known asmachine learning. Theintroduction of machine learning enabled computers to tackle problems involvingknowledge of the real world and make decisions that appear subjective. A simplemachine learning algorithm calledlogistic regressioncan determine whether torecommend cesarean delivery (Mor-Yosef et al., 1990). A simple machine learningalgorithm called naive Bayes can separate legitimate e-mail from spam e-mail.The performance of these simple machine learning algorithms depends heavilyon therepresentationof the data they are given. For example, when logisticregression is used to recommend cesarean delivery, the AI system does not examinethe patient directly. Instead, the doctor tells the system several pieces of relevantinformation, such as the presence or absence of a uterine scar. Each piece ofinformation included in the representation of the patient is known as afeature.Logistic regression learns how each of these features of the patient correlates withvarious outcomes. However, it cannot inﬂuence how features are deﬁned in anyway. If logistic regression were given an MRI scan of the patient, rather thanthe doctor’s formalized report, it would not be able to make useful predictions.Individual pixels in an MRI scan have negligible correlation with any complicationsthat might occur during delivery.
This dependence on representations is a general phenomenon that appearsthroughout computer science and even daily life. In computer science, operationssuch as searching a collection of data can proceed exponentially faster if the collec-tion is structured and indexed intelligently. People can easily perform arithmeticon Arabic numerals but ﬁnd arithmetic on Roman numerals much more timeconsuming. It is not surprising that the choice of representation has an enormouseﬀect on the performance of machine learning algorithms. For a simple visualexample, see ﬁgure 1.1.Many artiﬁcial intelligence tasks can be solved by designing the right set offeatures to extract for that task, then providing these features to a simple machinelearning algorithm. For example, a useful feature for speaker identiﬁcation fromsound is an estimate of the size of the speaker’s vocal tract. This feature gives astrong clue as to whether the speaker is a man, woman, or child.For many tasks, however, it is diﬃcult to know what features should beextracted. For example, suppose that we would like to write a program to detectcars in photographs. We know that cars have wheels, so we might like to use thepresence of a wheel as a feature. Unfortunately, it is diﬃcult to describe exactlywhat a wheel looks like in terms of pixel values. A wheel has a simple geometricshape, but its image may be complicated by shadows falling on the wheel, the sunglaring oﬀ the metal parts of the wheel, the fender of the car or an object in the
foreground obscuring part of the wheel, and so on.One solution to this problem is to use machine learning to discover not onlythe mapping from representation to output but also the representation itself.This approach is known asrepresentation learning. Learned representationsoften result in much better performance than can be obtained with hand-designedrepresentations. They also enable AI systems to rapidly adapt to new tasks, withminimal human intervention. A representation learning algorithm can discover agood set of features for a simple task in minutes, or for a complex task in hours tomonths. Manually designing features for a complex task requires a great deal ofhuman time and eﬀort; it can take decades for an entire community of researchers.The quintessential example of a representation learning algorithm is theau-toencoder. An autoencoder is the combination of anencoderfunction, whichconverts the input data into a diﬀerent representation, and adecoderfunction,which converts the new representation back into the original format. Autoencodersare trained to preserve as much information as possible when an input is runthrough the encoder and then the decoder, but they are also trained to make thenew representation have various nice properties. Diﬀerent kinds of autoencodersaim to achieve diﬀerent kinds of properties.When designing features or algorithms for learning features, our goal is usuallyto separate thefactors of variationthat explain the observed data. In this
context, we use the word “factors” simply to refer to separate sources of inﬂuence;the factors are usually not combined by multiplication. Such factors are often notquantities that are directly observed. Instead, they may exist as either unobservedobjects or unobserved forces in the physical world that aﬀect observable quantities.They may also exist as constructs in the human mind that provide useful simplifyingexplanations or inferred causes of the observed data. They can be thought of asconcepts or abstractions that help us make sense of the rich variability in the data.When analyzing a speech recording, the factors of variation include the speaker’sage, their sex, their accent and the words they are speaking. When analyzing animage of a car, the factors of variation include the position of the car, its color,and the angle and brightness of the sun.A major source of diﬃculty in many real-world artiﬁcial intelligence applicationsis that many of the factors of variation inﬂuence every single piece of data we areable to observe. The individual pixels in an image of a red car might be very closeto black at night. The shape of the car’s silhouette depends on the viewing angle.Most applications require us to disentangle the factors of variation and discard theones that we do not care about.Of course, it can be very diﬃcult to extract such high-level, abstract featuresfrom raw data. Many of these factors of variation, such as a speaker’s accent,can be identiﬁed only using sophisticated, nearly human-level understanding ofthe data. When it is nearly as diﬃcult to obtain a representation as to solve theoriginal problem, representation learning does not, at ﬁrst glance, seem to help us.Deep learningsolves this central problem in representation learning by intro-ducing representations that are expressed in terms of other, simpler representations.Deep learning enables the computer to build complex concepts out of simpler con-cepts. Figure 1.2 shows how a deep learning system can represent the concept ofan image of a person by combining simpler concepts, such as corners and contours,which are in turn deﬁned in terms of edges.The quintessential example of a deep learning model is the feedforward deepnetwork, ormultilayer perceptron(MLP). A multilayer perceptron is just amathematical function mapping some set of input values to output values. Thefunction is formed by composing many simpler functions. We can think of eachapplication of a diﬀerent mathematical function as providing a new representationof the input.The idea of learning the right representation for the data provides one per-spective on deep learning. Another perspective on deep learning is that depthenables the computer to learn a multistep computer program. Each layer of therepresentation can be thought of as the state of the computer’s memory after
executing another set of instructions in parallel. Networks with greater depth canexecute more instructions in sequence. Sequential instructions oﬀer great powerbecause later instructions can refer back to the results of earlier instructions. Ac-cording to this view of deep learning, not all the information in a layer’s activationsnecessarily encodes factors of variation that explain the input. The representationalso stores state information that helps to execute a program that can make senseof the input. This state information could be analogous to a counter or pointerin a traditional computer program. It has nothing to do with the content of theinput speciﬁcally, but it helps the model to organize its processing.There are two main ways of measuring the depth of a model. The ﬁrst view isbased on the number of sequential instructions that must be executed to evaluatethe architecture. We can think of this as the length of the longest path througha ﬂow chart that describes how to compute each of the model’s outputs givenits inputs. Just as two equivalent computer programs will have diﬀerent lengthsdepending on which language the program is written in, the same function maybe drawn as a ﬂowchart with diﬀerent depths depending on which functions weallow to be used as individual steps in the ﬂowchart. Figure 1.3 illustrates how thischoice of language can give two diﬀerent measurements for the same architecture.
Another approach, used by deep probabilistic models, regards the depth of amodel as being not the depth of the computational graph but the depth of thegraph describing how concepts are related to each other. In this case, the depthof the ﬂowchart of the computations needed to compute the representation ofeach concept may be much deeper than the graph of the concepts themselves.This is because the system’s understanding of the simpler concepts can be reﬁnedgiven information about the more complex concepts. For example, an AI systemobserving an image of a face with one eye in shadow may initially see only oneeye. After detecting that a face is present, the system can then infer that a secondeye is probably present as well. In this case, the graph of concepts includes onlytwo layers—a layer for eyes and a layer for faces—but the graph of computationsincludes 2nlayers if we reﬁne our estimate of each concept given the otherntimes.Because it is not always clear which of these two views—the depth of thecomputational graph, or the depth of the probabilistic modeling graph—is mostrelevant, and because diﬀerent people choose diﬀerent sets of smallest elementsfrom which to construct their graphs, there is no single correct value for thedepth of an architecture, just as there is no single correct value for the length ofa computer program. Nor is there a consensus about how much depth a modelrequires to qualify as “deep.” However, deep learning can be safely regarded as thestudy of models that involve a greater amount of composition of either learnedfunctions or learned concepts than traditional machine learning does.To summarize, deep learning, the subject of this book, is an approach to AI.Speciﬁcally, it is a type of machine learning, a technique that enables computersystems to improve with experience and data. We contend that machine learningis the only viable approach to building AI systems that can operate in complicatedreal-world environments. Deep learning is a particular kind of machine learningthat achieves great power and ﬂexibility by representing the world as a nestedhierarchy of concepts, with each concept deﬁned in relation to simpler concepts, andmore abstract representations computed in terms of less abstract ones. Figure 1.4illustrates the relationship between these diﬀerent AI disciplines. Figure 1.5 givesa high-level schematic of how each works.
1.1 Who Should Read This Book?This book can be useful for a variety of readers, but we wrote it with two targetaudiences in mind. One of these target audiences is university students (under-graduate or graduate) learning about machine learning, including those who arebeginning a career in deep learning and artiﬁcial intelligence research. The other
target audience is software engineers who do not have a machine learning or statis-tics background but want to rapidly acquire one and begin using deep learning intheir product or platform. Deep learning has already proved useful in many soft-ware disciplines, including computer vision, speech and audio processing, naturallanguage processing, robotics, bioinformatics and chemistry, video games, searchengines, online advertising and ﬁnance.This book has been organized into three parts to best accommodate a varietyof readers. Part I introduces basic mathematical tools and machine learningconcepts. Part II describes the most established deep learning algorithms, whichare essentially solved technologies. Part III describes more speculative ideas thatare widely believed to be important for future research in deep learning.
Readers should feel free to skip parts that are not relevant given their interestsor background. Readers familiar with linear algebra, probability, and fundamentalmachine learning concepts can skip part I, for example, while those who just wantto implement a working system need not read beyond part II. To help choose which
chapters to read, ﬁgure 1.6 provides a ﬂowchart showing the high-level organizationof the book.We do assume that all readers come from a computer science background. Weassume familiarity with programming, a basic understanding of computationalperformance issues, complexity theory, introductory level calculus and some of theterminology of graph theory.1.2 Historical Trends in Deep LearningIt is easiest to understand deep learning with some historical context. Rather thanproviding a detailed history of deep learning, we identify a few key trends:•Deep learning has had a long and rich history, but has gone by many names,reﬂecting diﬀerent philosophical viewpoints, and has waxed and waned inpopularity.•Deep learning has become more useful as the amount of available trainingdata has increased.•Deep learning models have grown in size over time as computer infrastructure(both hardware and software) for deep learning has improved.•Deep learning has solved increasingly complicated applications with increasingaccuracy over time.1.2.1 The Many Names and Changing Fortunes of Neural Net-worksWe expect that many readers of this book have heard of deep learning as an excitingnew technology, and are surprised to see a mention of “history” in a book about anemerging ﬁeld. In fact, deep learning dates back to the 1940s. Deep learning onlyappears to be new, because it was relatively unpopular for several years precedingits current popularity, and because it has gone through many diﬀerent names, onlyrecently being called “deep learning.” The ﬁeld has been rebranded many times,reﬂecting the inﬂuence of diﬀerent researchers and diﬀerent perspectives.A comprehensive history of deep learning is beyond the scope of this textbook.Some basic context, however, is useful for understanding deep learning. Broadlyspeaking, there have been three waves of development: deep learning known ascyberneticsin the 1940s–1960s, deep learning known asconnectionismin the
1980s–1990s, and the current resurgence under the name deep learning beginningin 2006. This is quantitatively illustrated in ﬁgure 1.7.Some of the earliest learning algorithms we recognize today were intended tobe computational models of biological learning, that is, models of how learninghappens or could happen in the brain. As a result, one of the names that deeplearning has gone by isartiﬁcial neural networks(ANNs). The correspondingperspective on deep learning models is that they are engineered systems inspiredby the biological brain (whether the human brain or the brain of another animal).While the kinds of neural networks used for machine learning have sometimesbeen used to understand brain function (Hinton and Shallice, 1991), they aregenerally not designed to be realistic models of biological function. The neuralperspective on deep learning is motivated by two main ideas. One idea is thatthe brain provides a proof by example that intelligent behavior is possible, and aconceptually straightforward path to building intelligence is to reverse engineer thecomputational principles behind the brain and duplicate its functionality. Another
CHAPTER 1. INTRODUCTIONperspective is that it would be deeply interesting to understand the brain and theprinciples that underlie human intelligence, so machine learning models that shedlight on these basic scientiﬁc questions are useful apart from their ability to solveengineering applications.The modern term “deep learning” goes beyond the neuroscientiﬁc perspectiveon the current breed of machine learning models. It appeals to a more generalprinciple of learning multiple levels of composition, which can be applied in machinelearning frameworks that are not necessarily neurally inspired.The earliest predecessors of modern deep learning were simple linear modelsmotivated from a neuroscientiﬁc perspective. These models were designed totake a set ofninput valuesx1, . . . , xnand associate them with an outputy.These models would learn a set of weightsw1, . . . , wnand compute their outputf(x, w) =x1w1+···+xnwn. This ﬁrst wave of neural networks research wasknown as cybernetics, as illustrated in ﬁgure 1.7.The McCulloch-Pitts neuron (McCulloch and Pitts, 1943) was an early modelof brain function. This linear model could recognize two diﬀerent categories ofinputs by testing whetherf(x, w) is positive or negative. Of course, for the modelto correspond to the desired deﬁnition of the categories, the weights needed to beset correctly. These weights could be set by the human operator. In the 1950s, theperceptron (Rosenblatt, 1958, 1962) became the ﬁrst model that could learn theweights that deﬁned the categories given examples of inputs from each category.Theadaptive linear element(ADALINE), which dates from about the sametime, simply returned the value off(x) itself to predict a real number (Widrowand Hoﬀ, 1960) and could also learn to predict these numbers from data.These simple learning algorithms greatly aﬀected the modern landscape of ma-chine learning. The training algorithm used to adapt the weights of the ADALINEwas a special case of an algorithm calledstochastic gradient descent. Slightlymodiﬁed versions of the stochastic gradient descent algorithm remain the dominanttraining algorithms for deep learning models today.Models based on thef(x, w) used by the perceptron and ADALINE are calledlinear models. These models remain some of the most widely used machinelearning models, though in many cases they are trained in diﬀerent ways than theoriginal models were trained.Linear models have many limitations. Most famously, they cannot learn theXOR function, wheref([0,1], w) = 1 andf([1,0], w) = 1 butf([1,1], w) = 0andf([0,0], w) = 0. Critics who observed these ﬂaws in linear models causeda backlash against biologically inspired learning in general (Minsky and Papert,1969). This was the ﬁrst major dip in the popularity of neural networks.
CHAPTER 1. INTRODUCTIONToday, neuroscience is regarded as an important source of inspiration for deeplearning researchers, but it is no longer the predominant guide for the ﬁeld.The main reason for the diminished role of neuroscience in deep learningresearch today is that we simply do not have enough information about the brainto use it as a guide. To obtain a deep understanding of the actual algorithms usedby the brain, we would need to be able to monitor the activity of (at the veryleast) thousands of interconnected neurons simultaneously. Because we are notable to do this, we are far from understanding even some of the most simple andwell-studied parts of the brain (Olshausen and Field, 2005).Neuroscience has given us a reason to hope that a single deep learning algorithmcan solve many diﬀerent tasks. Neuroscientists have found that ferrets can learn to“see” with the auditory processing region of their brain if their brains are rewiredto send visual signals to that area (Von Melchner et al., 2000). This suggests thatmuch of the mammalian brain might use a single algorithm to solve most of thediﬀerent tasks that the brain solves. Before this hypothesis, machine learningresearch was more fragmented, with diﬀerent communities of researchers studyingnatural language processing, vision, motion planning and speech recognition. Today,these application communities are still separate, but it is common for deep learningresearch groups to study many or even all these application areas simultaneously.We are able to draw some rough guidelines from neuroscience. The basicidea of having many computational units that become intelligent only via theirinteractions with each other is inspired by the brain. The neocognitron (Fukushima,1980) introduced a powerful model architecture for processing images that wasinspired by the structure of the mammalian visual system and later became thebasis for the modern convolutional network (LeCun et al., 1998b), as we will seein section 9.10. Most neural networks today are based on a model neuron calledtherectiﬁed linear unit. The original cognitron (Fukushima, 1975) introduceda more complicated version that was highly inspired by our knowledge of brainfunction. The simpliﬁed modern version was developed incorporating ideas frommany viewpoints, with Nair and Hinton (2010) and Glorot et al. (2011a) citingneuroscience as an inﬂuence, and Jarrett et al. (2009) citing more engineering-oriented inﬂuences. While neuroscience is an important source of inspiration, itneed not be taken as a rigid guide. We know that actual neurons compute verydiﬀerent functions than modern rectiﬁed linear units, but greater neural realismhas not yet led to an improvement in machine learning performance. Also, whileneuroscience has successfully inspired several neural network architectures, wedo not yet know enough about biological learning for neuroscience to oﬀer muchguidance for the learning algorithms we use to train these architectures.
"""
sentence = """
I was not unaware, Brutus, when I undertook to commit to Latin writing those subjects which philosophers of the highest genius and exquisite learning had treated in the Greek language, that this labor of mine would encounter various criticisms. For to some, and indeed men not entirely unlearned, this whole business of philosophizing is displeasing. Others, however, do not so much criticize it, if it is pursued more casually, but they do not think that so much enthusiasm and so much work should be spent on it. There will also be others, learned in Greek literature but contemptuous of Latin, who will say they prefer to spend their effort in reading Greek works. Finally, I suspect there will be some who call me to other kinds of literature, arguing that this type of writing, even if it is elegant, is nevertheless unbefitting my public position and dignity.

Against all of these, I think I must speak briefly. Although, indeed, a sufficient response has already been given to the critics of philosophy in that book in which philosophy was defended and praised by me, when it had been accused and criticized by Hortensius. Since that book seemed to be approved both by you and by those whom I judged capable of judging, I have undertaken more, fearing lest I might seem to have been able to arouse men's interest, but unable to sustain it. But as for those who, even if they approve of this activity, nevertheless want it done more moderately, they demand a difficult sort of moderation in a thing which, once admitted, cannot be checked or repressed; so that we might find those who call us away from philosophy entirely to be almost more reasonable than these men, who set a limit on infinite things and demand mediocrity in a subject that is better the greater it is.

For if wisdom can be attained, it must not only be acquired by us, but also enjoyed. Or if this is difficult, there is nevertheless no limit to seeking the truth, until you have found it; and weariness in the search is shameful, when that which is sought is the most beautiful thing of all. Indeed, if we take pleasure in writing, who is so envious as to draw us away from it? But if it is a labor, who is there to set a limit to another's industry? For just as Terence's Chremes is not unkind, who does not want his new neighbor "to dig or plow or, in short, to do any heavy lifting" —for he is not deterring him from industry, but from servile labor—so it is with these busybodies, who are offended by this labor of mine, which is not at all unpleasant to me.

It is more difficult, therefore, to satisfy those who say they despise Latin writings. Regarding them, this is the first thing at which I wonder: why their native tongue does not delight them in the most serious matters, when these same people willingly read Latin plays translated word-for-word from the Greek. For who is so hostile to the very name of Roman that he would spurn or reject the Medea of Ennius or the Antiopa of Pacuvius, because he says he delights in the same plays by Euripides [and hates Latin literature]? "Shall I," he says, "read Caecilius's Synephebi or Terence's Andria rather than Menander's version of both?"

I dissent from these people so much that, although Sophocles wrote an excellent Electra, I still think Atilius's poorly translated version is worth reading. Licinius called him "an iron writer"—a harsh one, I suppose, but a writer nonetheless, so he should be read. For to be completely unacquainted with our own poets is a mark of either the laziest indolence or the most delicate fastidiousness. To me, indeed, no one seems sufficiently learned to whom our own [literature] is unknown. Or do we read "Would that in the grove..." any less than the same line in Greek? But will it be displeasing for those things discussed by Plato about living well and happily to be explained in Latin?

But if we are not acting as mere translators, but are upholding those things said by those we approve of, and adding to them our own judgment and our own order of writing, what reason do they have to prefer the Greek works to these, which are both eloquently stated and are not [mere] translations from the Greek? For if they say that these subjects have already been treated by them [the Greeks], there is no reason for them to read even so many Greeks as they are accustomed to read. For what in Stoicism was overlooked by Chrysippus? Yet we read Diogenes, Antipater, Mnesarchus, Panaetius, many others, and especially our friend Posidonius. What? Does Theophrastus delight us only moderately when he treats topics previously treated by Aristotle? What? Do the Epicureans stop writing, according to their own judgment, about the same things which were written about by Epicurus and by the ancients? But if Greeks are read by Greeks on the same subjects composed in a different manner, why should our [authors] not be read by our [people]?

And yet, if I were to translate Plato or Aristotle just as our poets translated plays, I would, I believe, be doing a poor service to my fellow citizens, if I were to transfer those divine geniuses to their understanding [in that way]. But I have neither done this so far, nor do I think I am forbidden from doing it. Certain passages, indeed, I will translate, if it seems appropriate, and especially from those I just named, when it happens that it can be done fittingly, just as Ennius is accustomed [to do] from Homer, or Afranius from Menander. Nor indeed, like our Lucilius, will I object to everyone reading my work. Would that Persius were [alive]! Or Scipio and Rutilius even more so! Lucilius, fearing their judgment, says that he writes for the people of Tarentum, Consentia, and Sicily. He said this wittily, as with other things; but neither were there such learned men then whose judgment he had to labor for, and his writings are rather light, so that while his wit is supreme, his learning is moderate.

But what reader should I fear, when I dare to write to you, a man not inferior even to the Greeks in philosophy? Although I do this having been challenged by you yourself, in that most welcome book you sent me "On Virtue." But I believe it happens to some that they shrink from Latin works for this reason: because they have come across certain unpolished and rough works, written in Latin as bad translations from bad Greek. I agree with them, provided that they think the Greeks are not worth reading on these same subjects either. But as for good subjects, expressed gravely and elegantly in choice words, who would not read them? Unless he plainly wishes to be called a Greek, as Albucius was greeted in Athens by the praetor Scaevola.

The same Lucilius [describes] this incident with much charm and wit, in whose work Scaevola [speaks] brilliantly:

"You, Albucius, preferred to be called a Greek Rather than a Roman and a Sabine, A fellow citizen of Pontus, of Tritanus, of centurions, Illustrious men and standard-bearers. Therefore, as praetor in Athens, I salute you in Greek, As you preferred, when you approach me: 'Χαῖρε (Hail),' I say, 'Titus!' My lictors, my whole entourage, and my cohort [shout]: 'Χαῖρε (Hail), Titus!' From that moment, Albucius is my foe, my enemy."

But Mucius [Scaevola] was right. I, however, cannot wonder enough whence this insolent disdain for our native things arises. This is not the place to elaborate, but I feel and have often argued that the Latin language is not only not impoverished, as is commonly thought, but is even richer than Greek. For when have we—or I should say, our good orators or poets, at least after they had someone to imitate—lacked any ornament of speech, whether copious or elegant?

As for me, since I do not seem to have deserted my post in the forum—in its works, labors, and perils—in which I was placed by the Roman people, I certainly ought also to labor, as much as I can, to this end: that my fellow citizens may be more learned through my work, enthusiasm, and labor. And I should not fight so hard with those who prefer to read Greek, provided they actually read those works and don't just pretend to; and I should serve those who wish to use both literatures, or who, if they have their own, do not greatly miss the other.

But those who prefer that other things be written by me ought to be fair, because many things have already been written (so many that no one of our countrymen has written more), and perhaps more will be written, if life allows. And yet, anyone who makes a habit of diligently reading these things which I am committing to writing about philosophy will judge that nothing is more worth reading than these. For what in life is so worth seeking as all things in philosophy, and especially that which is sought in these books: what is the end, what is the extreme, what is the ultimate goal, to which all plans for living well and acting rightly should be referred? What does nature follow as the highest of things to be sought, and what does it flee from as the ultimate of evils? Since there is the greatest disagreement on this matter among the most learned men, who would think it foreign to whatever dignity one might attribute to me, to inquire what is best and truest in every duty of life?

Or, shall it be debated among the leaders of the state, P. Scaevola and Manius Manilius, whether the offspring of a female slave is to be considered profit, and will Marcus Brutus [your ancestor] disagree with them—because this is both a sharp-witted debate and not useless for the citizens' needs, and we read and will read those writings and others of the same kind with pleasure—and yet these matters, which contain all of life, will be neglected? For, though those [legal debates] may be more popular, these [philosophical ones] are certainly richer. Although, those who have read them will be free to judge this.

We, however, believe that this whole question of the ends of good and evil has been almost completely explained by us in these writings, in which, as much as we were able, we have pursued not only what was approved by us, but also what was said by each of the philosophical schools.

But to begin with the easiest, let the system of Epicurus come first, which is the most familiar to the majority. You will understand it as set forth by us in such a way that it is not usually explained more accurately even by those who approve of that school. For we wish to find the truth, not to refute some adversary. Moreover, the opinion of Epicurus concerning pleasure was once accurately defended by Lucius Torquatus, a man educated in every doctrine, and a response was given to him by me, while Gaius Triarius, a particularly serious and learned young man, was present at that discussion.

For when both of them had come to my estate at Cumae to pay their respects, at first we spoke a few words among ourselves about literature, for which both had the greatest enthusiasm. Then Torquatus said, "Since we have found you at leisure at last, I must certainly hear why it is that you—not that you hate our Epicurus, as those who disagree with him usually do—but certainly why you do not approve of him; the one man whom I believe alone saw the truth, liberated the minds of men from the greatest errors, and handed down all things that pertain to living well and happily. But I suppose that you, just like our friend Triarius, are less delighted by him because he neglected those rhetorical ornaments of Plato, Aristotle, and Theophrastus. For I can hardly be brought to believe that what he thought does not seem true to you."

"See how mistaken you are, Torquatus," I said. "The style of that philosopher does not offend me; for he both encompasses in words what he means and speaks plainly what I can understand. And yet, if a philosopher should offer eloquence, I would not spurn it; if he does not have it, I would not particularly demand it. It is in his content that he does not equally satisfy me, and indeed in several places. But, so many men, so many opinions; therefore, we can be mistaken." "Why then," he said, "does he not satisfy you? For I think you are a fair judge, provided you know well what he says."

"Unless," I said, "you think that Phaedrus or Zeno lied to me—both of whom I heard (though they impressed me with nothing, frankly, except their diligence)—all of Epicurus's doctrines are quite well known to me. And I frequently heard those men I named with our friend Atticus, while he [Atticus] admired both of them, and indeed was fond of Phaedrus. And every day we would discuss between us those things which we had heard, and there was never any dispute about what I understood, but only about what I approved."

"What is it then?" he said, "for I desire to hear what you do not approve of." "In the first place," I said, "in physics, in which he especially glories, he is, to begin with, entirely unoriginal. He repeats the doctrines of Democritus, changing very few things, but in such a way that those things he wishes to correct, he seems to me, at least, to corrupt. Democritus believes that atoms, as he calls them—that is, bodies indivisible on account of their solidity—are carried along in an infinite void (in which there is neither top nor bottom, middle nor end, nor extremity) in such a way that they cling together by their collisions, from which are formed all those things that exist and are perceived. And he holds that this motion of atoms has no beginning, but is understood to have existed from eternity.

Now, Epicurus, in those points where he follows Democritus, hardly ever errs. Although there are many things in both of them I do not approve of, especially this: that while two things ought to be sought in the study of nature—one, what the matter is from which each thing is made, and the other, what the force is which causes each thing—they discussed matter, but left out the efficient force and cause. But this is a common fault; the following are Epicurus's own peculiar blunders. For he believes that those same indivisible and solid bodies are carried downwards in a straight line by their own weight, and that this is the natural motion of all bodies.

Then, at that very point, the clever man, when it occurred to him that if all things were carried downwards perpendicularly and, as I said, in a straight line, it would never be possible for one atom to touch another, [so he introduced a fictitious idea]: he said that the atom swerves a very little bit, the smallest possible amount; and that thus are produced the combinations, couplings, and adhesions of atoms among themselves, from which the world and all the parts of the world, and all that is in it, are formed. Not only is this whole idea childishly fictitious, but it does not even achieve what he wants. For the swerve itself is imagined at whim—for he says the atom swerves without a cause, than which nothing is more disgraceful for a natural philosopher than to say that anything happens without a cause—and he arbitrarily deprived the atoms of that natural motion of all heavy bodies, which he himself had established, of seeking the lower place in a straight line; and yet, he did not attain the object for which he had invented all this.

For if all atoms swerve, none will ever cling together; or if some swerve while others are carried straight by their own tendency: first, this will be like assigning provinces to the atoms, deciding which are to move straight and which obliquely; and second, that same turbulent concourse of atoms—a point on which Democritus also gets stuck—will not be able to produce this ordered universe. Nor, indeed, is it worthy of a natural philosopher to believe that there is some 'minimum' (smallest part); which he surely never would have thought if he had preferred to learn geometry from his friend Polyaenus rather than to un-teach geometry even to him. The sun seems large to Democritus, as befits a man learned and perfected in geometry; to this man (Epicurus), it seems perhaps a foot wide; for he thinks it is just as large as it appears, or perhaps a little larger or smaller.

Thus, the things he changes, he spoils; the things he follows are all from Democritus. The atoms, the void, the images (which they call εἴδωλα [eidôla]), by whose impact we not only see but also think; infinity itself, which they call ἀπειρία [apeiria]—all this is from him (Democritus). Then there are the innumerable worlds, which are born and perish daily. And although I in no way approve of these ideas, I still would not have wanted Democritus, who is praised by others, to be criticized by this man, who followed him alone.

Now, in the other part of philosophy, which concerns inquiry and reasoning, which is called λογική (logic), your master is, as it seems to me at least, utterly unarmed and naked. He does away with definitions; he teaches nothing about division and classification; he gives no method for how reasoning is to be formulated and a conclusion drawn; he does not show how fallacies are to be resolved or ambiguities distinguished. He rests judgments of things on the senses, and if they have once approved something false as true, he thinks all judgment of true and false is overthrown.

But he confirms this above all, which 'nature itself,' as he says, 'discerns and approves'—that is, pleasure and pain: to these he refers everything we seek and everything we avoid. Although this doctrine belongs to Aristippus and is defended better and more freely by the Cyrenaics, I nevertheless judge it to be such that nothing seems more unworthy of a human being. For nature, it seems to me, has begotten and shaped us for certain greater things. And it is possible that I am wrong, but I truly believe that the famous Torquatus, who first earned this surname, did not tear the necklace from his foe in order to gain some bodily pleasure from it, nor did he fight the Latins at the Veseris in his third consulship for the sake of pleasure. And when he had his son beheaded, he even seems to have deprived himself of many pleasures, since he preferred the law of majesty and command to his own nature and paternal love.

What about that Torquatus who was consul with Gnaeus Octavius? When he employed that severity against his son—whom he had emancipated for adoption by Decimus Silanus—so that, when legates from Macedonia accused him, arguing that he had accepted bribes as praetor in the province, he ordered him to plead his case before him (his father), and after hearing both sides, pronounced that he did not seem to have behaved in his command as his ancestors had, and forbade him to come into his sight—does he seem to you to have thought at all about his own pleasures? But to omit the dangers, the labors, even the pain, which every good man undertakes for his country and his people, not only capturing no pleasure but even passing all pleasures by, preferring to undergo any pains rather than desert any part of his duty—let us come to those things which declare this no less, but seem more trivial.

What pleasure, Torquatus, do literature, the knowledge of history and events, the study of poets, the memorization of so many verses, bring to you, or to this Triarius? And do not tell me: 'These very things are a pleasure to me, just as they were to those Torquati.' Epicurus never defended it this way, nor did Metrodorus, nor any of them who had any wisdom or had learned those doctrines. And as to the common question of why there are so many Epicureans, there are other reasons, but this allures the multitude most: that they think he says that whatever is right and honorable is, in and of itself, a source of joy—that is, pleasure. These excellent people do not understand that the whole system is overturned if this is the case. For if it were granted that those things are delightful in their own right and by themselves, even if they have no reference to the body, then virtue and knowledge would also be desirable for their own sakes, which he (Epicurus) absolutely does not want.

These, then," I said, "are the doctrines of Epicurus that I do not approve of. For the rest, I would wish that he himself had been better instructed in learning—for he is, as you must also see, not sufficiently polished in those arts, the possessors of which are called 'erudite'—or else that he had not deterred others from such studies: although I see that you, at least, have by no means been deterred.

When I had said these things, more to provoke him than to speak my own mind, Triarius, smiling gently, said: "You, indeed, have practically removed Epicurus entirely from the chorus of philosophers. What have you left him, except that you understood what he meant, however he spoke? You said he was unoriginal in physics, and that not even those ideas were approved by you; if he wished to correct anything in them, he made them worse. He had no art of reasoning; in calling pleasure the highest good, he first of all failed to see the issue clearly, and secondly, this too was unoriginal, for Aristippus had said it before him and better. You added at the end that he was also an unlearned man."

"It is by no means possible, Triarius," I said, "that you not state what you disapprove of in one with whom you disagree. For what would prevent me from being an Epicurean, if I approved of what he said? Especially since learning those things would be child's play. For this reason, the criticisms of those who disagree with one another are not to be censured; but slander, insults, and then angry contentions and stubborn quarrels in debate—these always seem to me unworthy of philosophy."

Then Torquatus said: "I entirely agree; for one cannot debate without criticism, nor can one debate rightly with anger or stubbornness. But, if it is not troublesome, I have some things I would like to say in response to this." "Do you think," I said, "that I would have said all this, unless I wanted to hear you?" "Which, then, do you prefer?" he said. "That I run through the entire discipline of Epicurus, or that we inquire only about pleasure, which is the whole point of contention?" "That is indeed for you to decide," I said. "This is what I will do, then," he said. "I will explain one thing, and that the most important; we can speak of physics at another time. And I will, in fact, prove to you both that 'swerve' of the atoms and the size of the sun, and I will show that many of Democritus's errors were criticized and corrected by Epicurus. For now, I will speak about pleasure—nothing new, of course, but things which I am confident you yourself will approve." "Certainly," I said, "I will not be stubborn, and I will gladly agree with you, if you can prove to me what you say."

"I will prove it," he said, "provided you maintain that fairness which you are showing. But I prefer to use a continuous speech rather than to ask or be asked questions." "As you please," I said.

Then he began to speak. "First, therefore," he said, "I will proceed as the author of this discipline himself prefers: I will establish what and of what sort is the thing we are seeking, not because I think you are ignorant of it, but so that my speech may proceed with reason and method. We are asking, therefore, what is the 'extreme' and 'ultimate' of goods, which, in the opinion of all philosophers, ought to be such that all things are referred to it, while it is itself referred to nothing. This, Epicurus places in pleasure, which he wishes to be the highest good, and pain the highest evil; and he sets out to teach this thus:

Every animal, as soon as it is born, seeks pleasure and rejoices in it as the highest good; it shuns pain as the highest evil and, as much as it can, repels it from itself. It does this when it is not yet corrupted, with nature itself judging in an incorrupt and sound way. Therefore, he says there is no need for reason or debate as to why pleasure is to be sought and pain to be avoided. He thinks these things are felt, just as it is felt that fire is hot, snow is white, and honey is sweet; none of which need to be confirmed by elaborate arguments, it is enough merely to point them out. For there is a difference between a reasoned argument and conclusion, and a simple observation and pointing-out; by the former, hidden and, as it were, complex things are revealed; by the latter, things that are immediate and plain are judged. And since, if the senses are taken away from man, nothing remains, it is necessary that nature itself must judge what is in accordance with nature or contrary to it. And what does nature perceive or judge, by which to seek or avoid anything, other than pleasure and pain?

There are, however, some of our school who wish to teach these things more subtly, and who deny that it is enough for what is good or bad to be judged by sense, but that it can also be understood by the mind and by reason that pleasure is to be sought for its own sake and pain is to be avoided for its own sake. And so they say that there is in our minds this 'natural and innate conception,' so that we feel the one is to be sought, the other to be shunned. But others, with whom I agree—since many arguments are made by many philosophers as to why pleasure should not be counted among the goods, nor pain among the evils—do not think we should be overconfident in our cause, but believe that we must argue and discuss the matter accurately, and debate about pleasure and pain with carefully sought-out reasons.

But so that you may perceive whence all this error arises of those who accuse pleasure and praise pain, I will open up the whole matter and explain those very things which were said by that discoverer of truth and, as it were, architect of the happy life. For no one shuns, or hates, or flees pleasure itself, because it is pleasure, but because great pains follow for those who do not know how to pursue pleasure rationally. Nor, again, is there anyone who loves, or pursues, or desires to obtain pain itself, because it is pain, but because circumstances sometimes occur in which, by toil and pain, one may seek some great pleasure. To take a trivial example, which of us undertakes any laborious physical exercise, except to obtain some advantage from it? But who would have a right to find fault with a man who chooses to be in that pleasure which has no annoying consequences, or one who avoids that pain which produces no resultant pleasure?

But indeed, we do accuse and hold deserving of just hatred those who, softened and corrupted by the blandishments of present pleasures, blinded by desire, do not foresee what pains and troubles they are about to endure; and similar in fault are those who desert their duties through weakness of mind, that is, through the avoidance of toil and pain. And the distinction between these things is easy and straightforward. For in a free time, when our choice is unrestrained, and when nothing prevents us from doing what pleases us most, all pleasure is to be embraced, all pain to be repelled. But at certain times, either because of duties owed or the necessities of life, it will often happen that pleasures must be repudiated and annoyances not refused. And so, the wise man holds to this principle of selection in these matters: that he either rejects pleasures to obtain other greater ones, or he endures pains to repel worse ones.

Since I hold this opinion, what reason is there to fear that I cannot apply it to our ancestors, the Torquati? You recounted their deeds a little while ago, both from memory and also in a friendly and kindly way towards us; yet you did not bribe me by praising my ancestors, nor did you render me slower to respond. How, I ask, do you interpret their actions? Do you think that they either attacked an armed foe, or were so cruel towards their children and their own blood, that they thought nothing of their own advantages, nothing of their own benefits? But not even wild beasts do that—rush and charge in such a way that we do not understand where their movements and attacks are directed. Do you think that such distinguished men performed such great deeds without a cause?

What that cause was, I will see in a moment; meanwhile, I will hold this: if they did those things, which are without doubt praiseworthy, for some cause, then virtue itself was not, for them, the cause in itself. He tore the necklace from the foe. Yes, and he protected himself, so that he would not perish. But he faced great danger. Yes, in the sight of the army. What did he get from it? Praise and affection, which are the firmest defenses for living life without fear. He punished his son with death. If without cause, I should be sorry to be descended from so harsh and cruel a man. But if his purpose was, by his own pain, to sanction military discipline and to restrain the army in a most serious war by the fear of punishment, he was looking out for the safety of the citizens, in which he understood his own safety was contained.

And this principle extends widely. For that very point on which your speech—and especially yours, you who studiously pursue antiquities—is accustomed to boast, in commemorating famous and brave men and praising their deeds not for any profit, but for the splendor of moral honor itself: this whole idea is overturned when that principle of selection I just mentioned is established: that pleasures are either omitted for the sake of obtaining greater pleasures, or pains are undertaken for the sake of escaping greater pains.
"""



input_ids = tokenizer.encode(sentence, return_tensors="pt").to(model.device)[:, :4096]
print(len(input_ids[0]))
seq_len = input_ids.shape[1]

model_inputs = {
    "input_ids": input_ids,
    "attention_mask": torch.tril(torch.ones(seq_len, seq_len, dtype=torch.bool, device=model.device)).unsqueeze(0).unsqueeze(0),
    "full_hidden_states": True,
}

with torch.no_grad():
    hidden_states = model(**model_inputs).hidden_states#[0].float().cpu().numpy()

hidden_states = torch.stack(hidden_states, dim=0).squeeze()  # (num_layers, seq_len, hidden_size)

hh = []
layer_idx = list(range(n_model_layers // 8, n_model_layers, n_model_layers // 4))
print(f'Layer indices: {layer_idx}')
for i in range(3):
    hh.append(hidden_states[layer_idx, :, i].float().cpu().numpy())

print(hh[0].shape)

DrawFFT().draw_fft_individuals(hh, f"outcomes/rune_{model_name.split('/')[-1]}_fft_stem_log.png", log_scale=True, term=layer_idx)
DrawFFT().draw_fft_individuals(hh, f"outcomes/rune_{model_name.split('/')[-1]}_fft_stem_loglog.png", loglog_scale=True, term=layer_idx)

# for idx, h in enumerate(hidden_states):
#     hh = h[0].t().float().cpu().numpy()
#     DrawFFT().draw_fft_individual(hh[:36], f"outcomes/runb_fft_stem_log_{idx}.png", log_scale=True)
#     DrawFFT().draw_fft_individual(hh[:36], f"outcomes/runb_fft_stem_loglog_{idx}.png", loglog_scale=True)

